{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes for Sentiment Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be using [this](http://ai.stanford.edu/~amaas/data/sentiment/) dataset for binary sentiment classification. The dataset contains 25,000 highly polar movie reviews for training, and 25,000 for testing. To get the data:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`wget http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext \n",
    "import numpy as np\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = SparkContext.getOrCreate()\n",
    "path = \"/Users/Yimei/Desktop/winter/spark-nb/aclImdb/\"\n",
    "train_path = path + \"train/\"\n",
    "test_path = path + \"test/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_raw_pos = sc.textFile(train_path + \"pos/*.txt\")\n",
    "data_raw_neg = sc.textFile(train_path + \"neg/*.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'Bromwell High is a cartoon comedy. It ran at the same time as some other programs about school life, such as \"Teachers\". My 35 years in the teaching profession lead me to believe that Bromwell High\\'s satire is much closer to reality than is \"Teachers\". The scramble to survive financially, the insightful students who can see right through their pathetic teachers\\' pomp, the pettiness of the whole situation, all remind me of the schools I knew and their students. When I saw the episode in which a student repeatedly tried to burn down the school, I immediately recalled ......... at .......... High. A classic line: INSPECTOR: I\\'m here to sack one of your teachers. STUDENT: Welcome to Bromwell High. I expect that many adults of my age think that Bromwell High is far fetched. What a pity that it isn\\'t!'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# note that this is a whole review\n",
    "data_raw_pos.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample 20% of the data\n",
    "data_raw_pos = data_raw_pos.sample(False, 0.2, 1)\n",
    "data_raw_neg = data_raw_neg.sample(False, 0.2, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12500"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of partitions\n",
    "data_raw_pos.getNumPartitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You may OR may NOT want to repartition or coalesce\n",
    "# num_partitions = 3 or 4 times the number of CPUs\n",
    "num_partitions = 8\n",
    "data_raw_pos = data_raw_pos.repartition(num_partitions)\n",
    "data_raw_neg = data_raw_neg.repartition(num_partitions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2529\n",
      "2529\n"
     ]
    }
   ],
   "source": [
    "# count 2529 elements\n",
    "# this takes some time as the count is doing the action\n",
    "print(data_raw_pos.count())\n",
    "print(data_raw_neg.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training NB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'A',\n",
       " u'lot',\n",
       " u'of',\n",
       " u'people',\n",
       " u'are',\n",
       " u'saying',\n",
       " u'that',\n",
       " u'Al',\n",
       " u'Pacino',\n",
       " u'over']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# split into words (here we could filter stopwords, clean, romove punctuation)\n",
    "data_pos = data_raw_pos.flatMap(lambda x: x.split())\n",
    "data_pos.take(10)\n",
    "#want the whole bag of words thus flatmap it "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'A', 1),\n",
       " (u'lot', 1),\n",
       " (u'of', 1),\n",
       " (u'people', 1),\n",
       " (u'are', 1),\n",
       " (u'saying', 1),\n",
       " (u'that', 1),\n",
       " (u'Al', 1),\n",
       " (u'Pacino', 1),\n",
       " (u'over', 1)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# transform to value pairs to be able to count\n",
    "data_pos = data_pos.map(lambda x: (x, 1))\n",
    "data_pos.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'remastered', 1),\n",
       " (u'gangs.', 1),\n",
       " (u'anyways.I', 1),\n",
       " (u'wonderfull', 1),\n",
       " (u'four', 68),\n",
       " (u'Francisco,', 4),\n",
       " (u'demotes', 1),\n",
       " (u'HE-MAN', 1),\n",
       " (u'(sometimes', 2),\n",
       " (u'electricity', 5)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# counting number of words\n",
    "data_pos = data_pos.reduceByKey(lambda x,y:x+y)\n",
    "data_pos.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'Jojo', 2),\n",
       " (u'/>of', 3),\n",
       " (u\"syberberg's\", 1),\n",
       " (u'lungs.<br', 1),\n",
       " (u'Montford.', 1),\n",
       " (u'increase', 2),\n",
       " (u'jobbing', 1),\n",
       " (u'electricity', 1),\n",
       " (u\"'Breakfast\", 3),\n",
       " (u're-united', 1)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we can do all together\n",
    "data_neg = data_raw_neg.flatMap(lambda x: x.split()).map(lambda x: (x, 1)).reduceByKey(lambda x,y:x+y)\n",
    "data_neg.take(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How should we compute count(pos) and count(neg)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_pos = data_pos.map(lambda x: x[1]).reduce(lambda x,y:x+y)\n",
    "count_neg = data_neg.map(lambda x: x[1]).reduce(lambda x,y:x+y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(604442, 572063)\n"
     ]
    }
   ],
   "source": [
    "print(count_pos, count_neg)\n",
    "#here the number of the two clases are the same, half and half so we can simply ignore the log multiplication of that part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "101820\n"
     ]
    }
   ],
   "source": [
    "## Let's get V\n",
    "v1 = data_pos.map(lambda x: x[0]) # pos vocabulary\n",
    "v2 = data_neg.map(lambda x: x[0]) # neg vocabulary\n",
    "v = v1.union(v2)\n",
    "#v.count()\n",
    "v0 = v.distinct()\n",
    "V = v0.count()\n",
    "print(V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note that the denominators are different \n",
    "pos_denom = float(count_pos + V + 1)\n",
    "neg_denom = float(count_neg + V + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# log probabities\n",
    "pos_prob = data_pos.map(lambda x: (x[0], np.log(float(x[1] + 1)/pos_denom)))\n",
    "\n",
    "neg_prob = data_neg.map(lambda x: (x[0], np.log(float(x[1] + 1)/neg_denom))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'remastered', -12.77459578779308),\n",
       " (u'gangs.', -12.77459578779308),\n",
       " (u'anyways.I', -12.77459578779308),\n",
       " (u'wonderfull', -12.77459578779308),\n",
       " (u'four', -9.2336364637557669),\n",
       " (u'Francisco,', -11.858305055918926),\n",
       " (u'demotes', -12.77459578779308),\n",
       " (u'HE-MAN', -12.77459578779308),\n",
       " (u'(sometimes', -12.369130679684917),\n",
       " (u'electricity', -11.675983499124971)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_prob.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_prob = dict(pos_prob.collect())\n",
    "neg_prob = dict(neg_prob.collect())\n",
    "\n",
    "#change into a dictionary, easier to use to look up when throw in test set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# broadcast = shared by all nodes\n",
    "pos_prob_b = sc.broadcast(pos_prob)\n",
    "neg_prob_b = sc.broadcast(neg_prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2529\n",
      "2529\n"
     ]
    }
   ],
   "source": [
    "test_raw_pos = sc.textFile(test_path + \"pos/*.txt\")\n",
    "test_raw_neg = sc.textFile(test_path + \"neg/*.txt\")\n",
    "\n",
    "test_raw_pos = test_raw_pos.sample(False, 0.2, 1)\n",
    "test_raw_neg = test_raw_neg.sample(False, 0.2, 1)\n",
    "\n",
    "num_partitions = 8\n",
    "test_raw_pos = test_raw_pos.repartition(num_partitions)\n",
    "test_raw_neg = test_raw_neg.repartition(num_partitions)\n",
    "\n",
    "print(test_raw_pos.count())\n",
    "print(test_raw_neg.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Why this film was only released in 4 states is beyond me. I thought this film was a divine story. The name says it all: Seeing Other People. This movie has more logic than laughs, which I suppose is why it works so well. Common sense also makes an appearance in what would seem to be another puerile sex comedy. Alice is getting her feet frozen in the cold, when she feels irrationally about the way she might perform for her fiancé, not just sexually, but as a partner, and friend etc. This starts what seems to be an almost archetypal journey for the both of them. One fling after another leads to trouble, as if it wasn't a bad idea from the start. Witty dialogue and comic set-ups make this one funny as hell! Nicholson and Mohr set the tone of the film early on, and keep the promise they anticipate. Other highlights are Lauren Graham, Andy Richter, and Helen Slater(in her first theatrical film in 10 years!). Climax begins to take an insane turn, but a simple ending makes this one far more enjoyable than most movies today. Mohr fans will see something different in his Ed character, and fans of Helen Slater will enjoy her shiny moments of a quick, but excellent come-back. Any Richter takes home the award for most moralistic character. Romantic and funny, or just plain fun. Seeing Other People is a gem, which needs to be noticed.\n"
     ]
    }
   ],
   "source": [
    "doc = test_raw_pos.first()\n",
    "print(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred_class(doc):\n",
    "    words = doc.split(\" \")\n",
    "    counts = Counter(words)\n",
    "    log_pos = 0.0\n",
    "    log_neg = 0.0\n",
    "    for w in counts:\n",
    "        log_pos += counts[w]* pos_prob_b.value.get(w, np.log(1.0/pos_denom))\n",
    "        log_neg += counts[w]* neg_prob_b.value.get(w, np.log(1.0/neg_denom))\n",
    "    if log_pos > log_neg:\n",
    "        return \"pos\"\n",
    "    return \"neg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'pos'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_class(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['pos', 'pos', 'pos', 'pos', 'pos', 'pos', 'neg', 'neg', 'pos', 'pos']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pos_res = test_raw_pos.map(pred_class)\n",
    "test_pos_res.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'neg': 575, 'pos': 1954}\n"
     ]
    }
   ],
   "source": [
    "test_pos_res = test_raw_pos.map(pred_class).map(lambda x: (x, 1)).reduceByKey(lambda x,y:x+y)\n",
    "pos_results = dict(test_pos_res.collect())\n",
    "print(pos_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'neg': 2153, 'pos': 376}\n"
     ]
    }
   ],
   "source": [
    "test_neg_res = test_raw_neg.map(pred_class).map(lambda x: (x, 1)).reduceByKey(lambda x,y:x+y)\n",
    "neg_results = dict(test_neg_res.collect())\n",
    "print(neg_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.811981020166\n"
     ]
    }
   ],
   "source": [
    "# compute accuracy\n",
    "total = sum(neg_results.values()) + sum(pos_results.values())\n",
    "acc = float(neg_results[\"neg\"] + pos_results[\"pos\"]) / float(total)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  },
  "latex_envs": {
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 0
  },
  "toc": {
   "nav_menu": {
    "height": "84px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
