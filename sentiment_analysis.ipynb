{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in the data into test and train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#path = \"/Users/Yimei/Desktop/spring1/ml2/data/aclImdb/\"\n",
    "path = \"/Users/Yimei/Desktop/spring1/ml2/data/aclImdb/\"\n",
    "names = ['neg','pos']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def texts_from_folders(src, names):\n",
    "    texts,labels = [],[]\n",
    "    for idx,name in enumerate(names):\n",
    "        path = os.path.join(src, name)\n",
    "        for fname in sorted(os.listdir(path)):\n",
    "            fpath = os.path.join(path, fname)\n",
    "            texts.append(open(fpath).read())\n",
    "            labels.append(idx)\n",
    "    return texts,np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn,trn_y = texts_from_folders(path+'train',names)\n",
    "val,val_y = texts_from_folders(path+'test',names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(list,\n",
       " \"Story of a man who has unnatural feelings for a pig. Starts out with a opening scene that is a terrific example of absurd comedy. A formal orchestra audience is turned into an insane, violent mob by the crazy chantings of it's singers. Unfortunately it stays absurd the WHOLE time with no general narrative eventually making it just too off putting. Even those from the era should be turned off. The cryptic dialogue would make Shakespeare seem easy to a third grader. On a technical level it's better than you might think with some good cinematography by future great Vilmos Zsigmond. Future stars Sally Kirkland and Frederic Forrest can be seen briefly.\")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(trn), trn[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenizing with spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import string\n",
    "import re\n",
    "from spacy.symbols import ORTH\n",
    "from __future__ import unicode_literals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "re_br = re.compile(r'<\\s*br\\s*/?>', re.IGNORECASE)\n",
    "def sub_br(x): return re_br.sub(\"\\n\", x)\n",
    "\n",
    "my_tok = spacy.load('en')\n",
    "def spacy_tok(x): return [tok.text for tok in my_tok.tokenizer(sub_br(x))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_trial = [spacy_tok(w.lower()) for w in trn[:3]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating embedding features - average embedding feature for each review\n",
    "\n",
    "from the https://nlp.stanford.edu/projects/glove/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "globe_path = '/Users/Yimei/data/glove/glove.6B/glove.6B.300d.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_word_embedings(file =globe_path):\n",
    "    embeddings = {}\n",
    "    with open(file, 'r') as infile:\n",
    "        for line in infile:\n",
    "            values = line.split()\n",
    "            embeddings[values[0]] = np.asarray(values[1:], dtype='float32')\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = load_word_embedings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "400000"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(embeddings.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /Users/Yimei/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    }
   ],
   "source": [
    "# get stop words\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "stops = set(stopwords.words(\"english\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modified from https://www.kaggle.com/anokas/data-analysis-xgboost-starter-0-35460-lb\n",
    "def get_non_stopwords(s):\n",
    "    \"\"\"Returns a list of non-stopwords\"\"\"\n",
    "    return {x:1 for x in spacy_tok(s.lower()) if x not in stops}.keys()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_features(s, embeddings=embeddings, emb_size=300):\n",
    "    words = get_non_stopwords(s)\n",
    "    words = [w for w in words if w.isalpha() and w in embeddings]\n",
    "    if len(words) == 0:\n",
    "        return np.hstack([np.zeros(emb_size)])\n",
    "    M = np.array([embeddings[w] for w in words])\n",
    "    return M.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_trn = np.array([sentence_features(x) for x in trn])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_val = np.array([sentence_features(x) for x in val])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 300)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_trn.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit XGBoost with average feature embedding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-logloss:0.679729\tvalid-logloss:0.681471\n",
      "Multiple eval metrics have been passed: 'valid-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until valid-logloss hasn't improved in 50 rounds.\n",
      "[50]\ttrain-logloss:0.412146\tvalid-logloss:0.472889\n",
      "[100]\ttrain-logloss:0.327442\tvalid-logloss:0.423206\n",
      "[150]\ttrain-logloss:0.282454\tvalid-logloss:0.40227\n",
      "[200]\ttrain-logloss:0.25224\tvalid-logloss:0.391278\n",
      "[250]\ttrain-logloss:0.230545\tvalid-logloss:0.38444\n",
      "[300]\ttrain-logloss:0.212875\tvalid-logloss:0.380176\n",
      "[350]\ttrain-logloss:0.198953\tvalid-logloss:0.377312\n"
     ]
    }
   ],
   "source": [
    "xgb_pars = {\"min_child_weight\": 50, \"eta\": 0.05, \"max_depth\": 8,\n",
    "            \"subsample\": 0.8, \"silent\" : 1, \"nthread\": 4,\n",
    "            \"eval_metric\": \"logloss\", \"objective\": \"binary:logistic\"}\n",
    "\n",
    "d_train = xgb.DMatrix(x_trn, label=trn_y)\n",
    "d_val = xgb.DMatrix(x_val, label=val_y)\n",
    "\n",
    "watchlist = [(d_train, 'train'), (d_val, 'valid')]\n",
    "\n",
    "bst = xgb.train(xgb_pars, d_train, 400, watchlist, early_stopping_rounds=50, verbose_eval=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "#report training and validation log loss\n",
    "from sklearn.metrics import log_loss\n",
    "prob_trn = bst.predict(d_train)\n",
    "prob_val = bst.predict(d_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_loss_trn = log_loss(trn_y, prob_trn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_loss_val = log_loss(val_y, prob_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_loss_trn: 0.186594901618 ; log_loss_val: 0.37474418679\n"
     ]
    }
   ],
   "source": [
    "print \"log_loss_trn:\",log_loss_trn, \"; log_loss_val:\",log_loss_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoding with one-hot-encoded bag of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "veczr = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_term_doc = veczr.fit_transform(trn)\n",
    "#transform: use the previous created bag\n",
    "val_term_doc = veczr.transform(val)\n",
    "#use the previously created model, here is trn_term_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<25000x74849 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 3445861 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trn_term_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<25000x74849 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 3339346 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_term_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert sparse matrix to pandas dataframe\n",
    "train_df = pd.SparseDataFrame(trn_term_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fill the nan with 0\n",
    "train_df_filled_na = train_df.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_df = pd.SparseDataFrame(val_term_doc)\n",
    "val_df_filled_na = val_df.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'augustine', u'augusto', u'augustus', u'auh', u'auie']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = veczr.get_feature_names(); vocab[5000:5005]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit XGBoost with bag of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_pars = {\"min_child_weight\": 50, \"eta\": 0.05, \"max_depth\": 8,\n",
    "            \"subsample\": 0.8, \"silent\" : 1,\n",
    "            \"eval_metric\": \"logloss\", \"objective\": \"binary:logistic\"}\n",
    "\n",
    "\n",
    "d_train = xgb.DMatrix(trn_term_doc, label=trn_y)\n",
    "d_val = xgb.DMatrix(val_term_doc, label=val_y)\n",
    "\n",
    "\n",
    "watchlist = [(d_train, 'train'), (d_val, 'valid')]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-logloss:0.681085\tvalid-logloss:0.681127\n",
      "Multiple eval metrics have been passed: 'valid-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until valid-logloss hasn't improved in 50 rounds.\n",
      "[50]\ttrain-logloss:0.479689\tvalid-logloss:0.489127\n",
      "[100]\ttrain-logloss:0.413813\tvalid-logloss:0.431985\n",
      "[150]\ttrain-logloss:0.374572\tvalid-logloss:0.400454\n",
      "[200]\ttrain-logloss:0.347537\tvalid-logloss:0.380255\n",
      "[250]\ttrain-logloss:0.327139\tvalid-logloss:0.365904\n",
      "[300]\ttrain-logloss:0.311089\tvalid-logloss:0.355359\n",
      "[350]\ttrain-logloss:0.297842\tvalid-logloss:0.347335\n",
      "[399]\ttrain-logloss:0.286724\tvalid-logloss:0.341357\n"
     ]
    }
   ],
   "source": [
    "bst = xgb.train(xgb_pars, d_train, 400, watchlist, early_stopping_rounds=50, verbose_eval=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_trn = bst.predict(d_train)\n",
    "prob_val = bst.predict(d_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import log_loss\n",
    "log_loss_trn = log_loss(trn_y, prob_trn)\n",
    "log_loss_val = log_loss(val_y, prob_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_loss_trn: 0.286724204693 ; log_loss_val: 0.341357342403\n"
     ]
    }
   ],
   "source": [
    "print \"log_loss_trn:\",log_loss_trn, \"; log_loss_val:\",log_loss_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
